# Grok Chat App

A lightweight LLM-powered chat application built to demonstrate end-to-end integration of a conversational AI system, including prompt handling, conversation flow, and a simple web interface.
This project focuses on the core mechanics of building an AI chat system rather than UI complexity.

## Overview

Grok Chat App allows users to interact with a large language model through a clean chat interface. The application handles user input, formats prompts, sends requests to the LLM backend, and returns model-generated responses in real time.
It is designed as a foundation for more advanced conversational AI systems.

## Key Features

- Interactive chat interface for multi-turn conversations
- LLM integration for natural language responses
- Modular code structure for easy extension
- Simple and lightweight architecture suitable for rapid prototyping

## Tech Stack

- **Language:** Python
- **Frontend:** Streamlit
- **LLM Integration:** Custom client for Grok-style / LLM API
- **Environment Management:** Python virtual environment

---

## Project Structure

grok-chat-app/
│
├── app.py # Streamlit application entry point
├── grok_client.py # LLM API client and request handling
├── requirements.txt # Project dependencies
└── README.md # Project documentation

